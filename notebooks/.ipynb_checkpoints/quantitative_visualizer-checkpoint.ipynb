{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2c4f5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, copy, os, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# for SmoothGrad saliency maps (DO NOT USE MAGNITUDE!)\n",
    "from gradients import SmoothGrad\n",
    "\n",
    "# for loading datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
    "\n",
    "# custom utilities + optimized resnets\n",
    "import utils\n",
    "from resnet import resnet20, resnet32, resnet44\n",
    "\n",
    "# no fancy tricks -- let's keep it simple\n",
    "train_transforms = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "batch_size = 256\n",
    "\n",
    "# create a directory for our figures\n",
    "if \"figures\" not in os.listdir():\n",
    "    os.mkdir(\"figures\")\n",
    "    \n",
    "# subdirectory for our qualitative figures\n",
    "if \"quantitative\" not in os.listdir(\"figures\"):\n",
    "    os.mkdir(\"figures/quantitative\")\n",
    "    \n",
    "# DO NOT USE GPU FOR SALIENCY MAPS\n",
    "device = torch.device(\"cpu\")\n",
    "    \n",
    "# friendly colors\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "          '#f781bf', '#a65628', '#984ea3',\n",
    "          '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "# command-line arguments - let's go 10 IMAGES PER CLASS\n",
    "dataset = \"MNIST\" # [\"MNIST\", \"FashionMNIST\", \"CIFAR10\"][int(sys.argv[1])] # either 0, 1, or 2\n",
    "difficulty_val = \"easiest\" # [\"easiest\", \"hardest\", \"overall\"][int(sys.argv[2])] # either 0, 1, or 2\n",
    "split_val = \"train\" # [\"train\", \"test\"][int(sys.argv[3])] # either 0 or 1\n",
    "class_label_val = 0 # int(sys.argv[4]) # either 0, 1, 2, ..., or 9\n",
    "batch_idx = 0 # int(sys.argv[5]) # either 0, 1, 2, ..., or 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "115d58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the appropriate dataset + scores\n",
    "if dataset == \"MNIST\":\n",
    "\n",
    "    # load our training and test data\n",
    "    data_train = MNIST(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "    data_test = MNIST(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "\n",
    "    # load in our log files too\n",
    "    train_scores = pd.read_csv(\"logs/mnist_train_scores.csv\")\n",
    "    test_scores = pd.read_csv(\"logs/mnist_test_scores.csv\")\n",
    "    \n",
    "elif dataset == \"FashionMNIST\":\n",
    "    \n",
    "    # load our training and test data\n",
    "    data_train = FashionMNIST(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "    data_test = FashionMNIST(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "\n",
    "    # load in our log files too\n",
    "    train_scores = pd.read_csv(\"logs/fashion-mnist_train_scores.csv\")\n",
    "    test_scores = pd.read_csv(\"logs/fashion-mnist_test_scores.csv\")\n",
    "    \n",
    "elif dataset == \"CIFAR10\":\n",
    "    \n",
    "    # load our training and test data\n",
    "    data_train = CIFAR10(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "    data_test = CIFAR10(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "\n",
    "    # load in our log files too\n",
    "    train_scores = pd.read_csv(\"logs/cifar10_train_scores.csv\")\n",
    "    test_scores = pd.read_csv(\"logs/cifar10_test_scores.csv\")\n",
    "\n",
    "# compute the difficulties of each train and test point\n",
    "train_difficulties = train_scores[train_scores.columns[4:]].mean(axis=0).values\n",
    "test_difficulties = test_scores[test_scores.columns[4:]].mean(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "70882b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f001eadf3d4c1f89e3b4c516074435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set a seed\n",
    "np.random.seed(858)\n",
    "torch.manual_seed(858)\n",
    "\n",
    "# how many images are we looking at per class?\n",
    "N_SAMPLES = 100\n",
    "\n",
    "# are we looking at easiest, hardest, or overall?\n",
    "for difficulty in [difficulty_val]:\n",
    "\n",
    "    # go thru both train + test splits\n",
    "    for split in [split_val]:\n",
    "        \n",
    "        # create our subplots here!\n",
    "    \n",
    "        # go thru each of our classes\n",
    "        for class_label in [class_label_val]:\n",
    "\n",
    "            # get the N_SAMPLES images that correspond to difficulty + class_label + split\n",
    "            if split == \"train\":\n",
    "                \n",
    "                # query all data points + difficulties corres. to this class, pick our N_SAMPLES\n",
    "                if dataset == \"CIFAR10\":\n",
    "                    class_idxs = np.argwhere(np.array(data_train.targets) == class_label).flatten()\n",
    "                else:\n",
    "                    class_idxs = np.argwhere(data_train.targets.numpy() == class_label).flatten()\n",
    "                class_train_difficulties = train_difficulties[class_idxs]\n",
    "                \n",
    "                # pick our indices\n",
    "                if difficulty == \"hardest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_train_difficulties)][:N_SAMPLES]\n",
    "                elif difficulty == \"easiest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_train_difficulties)][-N_SAMPLES:]\n",
    "                elif difficulty == \"overall\":\n",
    "                    class_sample_idxs = np.random.choice(class_idxs, size=N_SAMPLES, replace=False)\n",
    "                    \n",
    "            elif split == \"test\":\n",
    "                \n",
    "                # query all data points + difficulties that correspond to this class\n",
    "                if dataset == \"CIFAR10\":\n",
    "                    class_idxs = np.argwhere(np.array(data_test.targets) == class_label).flatten()\n",
    "                else:\n",
    "                    class_idxs = np.argwhere(data_test.targets.numpy() == class_label).flatten()\n",
    "                class_test_difficulties = test_difficulties[class_idxs]\n",
    "                \n",
    "                # pick our indices\n",
    "                if difficulty == \"hardest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_test_difficulties)][:N_SAMPLES]\n",
    "                elif difficulty == \"easiest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_test_difficulties)][-N_SAMPLES:]\n",
    "                elif difficulty == \"overall\":\n",
    "                    class_sample_idxs = np.random.choice(class_idxs, size=N_SAMPLES, replace=False)\n",
    "                \n",
    "            # go thru each of our images + compute the 450 saliency maps on this batch of 10 images!\n",
    "            for class_sample_idx in class_sample_idxs[batch_idx*10:(batch_idx*10)+10]:\n",
    "                \n",
    "                # get the image that we should be working with, reshape + move to GPU\n",
    "                img = data_train[class_sample_idx][0] if split == \"train\" else data_test[class_sample_idx][0]\n",
    "                img = img.reshape(1, *img.shape)\n",
    "                img = img.to(device)\n",
    "                \n",
    "                # for CIFAR10, we need CNN(25, 47, 100), RESNET(20,32,44)\n",
    "                if dataset == \"CIFAR10\":\n",
    "                    model_packs = [(utils.CIFAR_CNN25K(), \"cnn_params=025k\"), \n",
    "                                   (utils.CIFAR_CNN47K(), \"cnn_params=047k\"),\n",
    "                                   (utils.CIFAR_CNN100K(), \"cnn_params=100k\"),\n",
    "                                   (resnet20(), \"resnet_variant=20\"),\n",
    "                                   (resnet32(), \"resnet_variant=32\"),\n",
    "                                   (resnet44(), \"resnet_variant=44\")]\n",
    "                \n",
    "                # for MNIST + FashionMNIST, generate saliencies for all 9 models MLP(1,2,3), CNN(2,3,4), RESNET(20,32,44)\n",
    "                elif dataset != \"CIFAR10\":\n",
    "                    model_packs = [(utils.MNIST_MLP(num_layers=1, data_dim=1024), \"mlp_num-layers=1\"), \n",
    "                                   (utils.MNIST_MLP(num_layers=2, data_dim=1024), \"mlp_num-layers=2\"),\n",
    "                                   (utils.MNIST_MLP(num_layers=3, data_dim=1024), \"mlp_num-layers=3\"),\n",
    "                                   (utils.MNIST_CNN(num_modules=2), \"cnn_num-modules=2\"), \n",
    "                                   (utils.MNIST_CNN(num_modules=3), \"cnn_num-modules=3\"),\n",
    "                                   (utils.MNIST_CNN(num_modules=4), \"cnn_num-modules=4\"),\n",
    "                                   (resnet20(), \"resnet_variant=20\"),\n",
    "                                   (resnet32(), \"resnet_variant=32\"),\n",
    "                                   (resnet44(), \"resnet_variant=44\")]\n",
    "                    \n",
    "                    \n",
    "\n",
    "                # create a dictionary for the STACKED saliency maps for each of our 9x models\n",
    "                saliency_maps = {}\n",
    "\n",
    "                # go thru all 6x or 9x of our models, all 50 seeds apiece\n",
    "                for model, model_desc in model_packs:\n",
    "\n",
    "                    # create an entry in our dictionary for this model + iterate thru the seeds\n",
    "                    saliency_maps[model_desc] = []\n",
    "                    for seed in range(50):\n",
    "\n",
    "                        # load in the correct weights + set to eval mode\n",
    "                        model.load_state_dict(torch.load(f\"models/{dataset}/{model_desc}_seed={str(seed).zfill(3)}/099.pth\", \n",
    "                                                         map_location=\"cpu\"))\n",
    "                        model.eval(); model.to(device)\n",
    "\n",
    "                        # compute our SmoothGrad saliency map, accounting for resnet dimensions\n",
    "                        smooth_grad = SmoothGrad(pretrained_model=model, cuda=False, n_samples=50, magnitude=False)\n",
    "                        if (\"resnet\" in model_desc) and (dataset != \"CIFAR10\"):\n",
    "                            saliency_map = smooth_grad(torch.cat([img, img, img], dim=1), index=None)\n",
    "                        else:\n",
    "                            saliency_map = smooth_grad(img, index=None)\n",
    "                        saliency_map_2d = np.sum(saliency_map, axis=0)\n",
    "\n",
    "                        # add to our dictionary\n",
    "                        saliency_maps[model_desc].append(copy.deepcopy(saliency_map_2d))\n",
    "\n",
    "                # save our object as a .pickle so that we can load it for analyses later\n",
    "                with open(f\"maps/{dataset}/{fname}\", \"wb\") as file:\n",
    "                    pickle.dump(obj=saliency_maps, file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Afterburner)",
   "language": "python",
   "name": "afterburner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
