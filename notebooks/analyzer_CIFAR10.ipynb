{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f0223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, copy, os, shutil, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from resnet import resnet20, resnet32, resnet44\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for loading datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
    "\n",
    "# make a directory for logs\n",
    "if \"logs\" not in os.listdir():\n",
    "    os.mkdir(\"logs\")\n",
    "    \n",
    "# NO FANCY TRICKS -- JUST RESIZE TO 32 x 32!\n",
    "train_transforms = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "    \n",
    "# let's set a batch size\n",
    "batch_size = 512\n",
    "\n",
    "# USE A GPU IF POSSIBLE!\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13adad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing Epoch 100 of 100 on Model 300 of 300 in 12.115 seconds.\n"
     ]
    }
   ],
   "source": [
    "# for CIFAR10, let's see which train and test points each model got correct\n",
    "\n",
    "# begin by loading our data\n",
    "data_train = CIFAR10(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "data_test = CIFAR10(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# create a dataframe with N + 4 columns (model-name + variant + seed)\n",
    "cifar_train_scores = pd.DataFrame(data=None, columns=[\"arch\", \"variant\", \"seed\", \"epoch\"] \\\n",
    "                                  + list(np.arange(50000)))\n",
    "cifar_test_scores = pd.DataFrame(data=None, columns=[\"arch\", \"variant\", \"seed\", \"epoch\"] \\\n",
    "                                  + list(np.arange(10000)))\n",
    "\n",
    "# what models do we have available for this dataset?\n",
    "model_names = [f for f in sorted(os.listdir(\"models/CIFAR10\")) if \"seed\" in f]\n",
    "\n",
    "# go thru each of our model\n",
    "for model_num, model_name in enumerate(model_names):\n",
    "    \n",
    "    # start time\n",
    "    start = time.time()\n",
    "    \n",
    "    # first figure out what architecture we need to be loading\n",
    "    if \"cnn\" in model_name:\n",
    "        \n",
    "        # how many parameters do we have?\n",
    "        variant = int(model_name.split(\"params=\")[1].split(\"k\")[0])\n",
    "        seed = int(model_name.split(\"seed=\")[1])\n",
    "        model_arch = \"cnn\"\n",
    "        \n",
    "        # load the appropriate architecture\n",
    "        if variant == 25:\n",
    "            model = utils.CIFAR_CNN25K()\n",
    "        elif variant == 47:\n",
    "            model = utils.CIFAR_CNN47K()\n",
    "        elif variant == 100:\n",
    "            model = utils.CIFAR_CNN100K()\n",
    "        \n",
    "    elif \"resnet\" in model_name:\n",
    "        \n",
    "        # which resnet variant are we loading?\n",
    "        variant = int(model_name.split(\"variant=\")[1].split(\"_\")[0])\n",
    "        seed = int(model_name.split(\"seed=\")[1])\n",
    "        model_arch = \"resnet\"\n",
    "        \n",
    "        # load the appropriate architecture\n",
    "        if variant == 20:\n",
    "            model = resnet20()\n",
    "        elif variant == 32:\n",
    "            model = resnet32()\n",
    "        elif variant == 44:\n",
    "            model = resnet44()\n",
    "            \n",
    "    # create our row header for this row\n",
    "    header = [model_arch, variant, seed]\n",
    "    \n",
    "    # REVISION: ONLY LOOKING AT THE LAST EPOCH:\n",
    "    for epoch in range(99, 100):\n",
    "        \n",
    "        # load in the weights for this epoch\n",
    "        model.load_state_dict(torch.load(f\"models/CIFAR10/{model_name}/{str(epoch).zfill(3)}.pth\"))\n",
    "        model.to(device); model.eval()\n",
    "        \n",
    "        ###### TRAINING SET METRICS\n",
    "        \n",
    "        # create a list of one-hot encoded accuracies\n",
    "        train_accs = np.array([])\n",
    "        \n",
    "        # compute accuracy on training set\n",
    "        for data in tqdm(trainloader):\n",
    "            \n",
    "            # unpack our x's and y's -- concatenate if necessary\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # do not use grad - make our predictions + record our accuracies\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                train_accs = np.concatenate([train_accs, (predictions == labels).cpu().numpy()])\n",
    "            \n",
    "        # add to our row\n",
    "        cifar_train_scores.loc[len(cifar_train_scores.index)] = header + [epoch] + list(train_accs)\n",
    "        \n",
    "        ###### TESTING SET METRICS\n",
    "        \n",
    "        # create a list of one-hot encoded accuracies\n",
    "        test_accs = np.array([])\n",
    "        \n",
    "        # compute accuracy on the TEST set\n",
    "        for data in tqdm(testloader):\n",
    "            \n",
    "            # unpack our x's and y's -- concatenate if necessary\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # do not use grad - make our predictions + record our accuracies\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                test_accs = np.concatenate([test_accs, (predictions == labels).cpu().numpy()])\n",
    "            \n",
    "        # add to our row\n",
    "        cifar_test_scores.loc[len(cifar_test_scores.index)] = header + [epoch] + list(test_accs)\n",
    "        \n",
    "    # compute end time\n",
    "    end = time.time()\n",
    "        \n",
    "    # status update\n",
    "    if (model_num + 1) % 5 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Finished processing Epoch {str(epoch + 1).zfill(3)} of 100 on Model {str(model_num + 1).zfill(3)} of 300 in {np.round(end - start, 3)} seconds.\")\n",
    "\n",
    "# save our logs at the very end\n",
    "cifar_train_scores.to_csv(\"logs/cifar10_train_scores.csv\", index=False)\n",
    "cifar_test_scores.to_csv(\"logs/cifar10_test_scores.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Afterburner)",
   "language": "python",
   "name": "afterburner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
