{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "10e67044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, copy, os, shutil\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# for SmoothGrad saliency maps (DO NOT USE MAGNITUDE!)\n",
    "from gradients import SmoothGrad\n",
    "\n",
    "# for loading datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
    "\n",
    "# custom utilities + optimized resnets\n",
    "import utils\n",
    "from resnet import resnet20, resnet32, resnet44\n",
    "\n",
    "# no fancy tricks -- let's keep it simple\n",
    "train_transforms = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "batch_size = 256\n",
    "\n",
    "# create a directory for our figures\n",
    "if \"figures\" not in os.listdir():\n",
    "    os.mkdir(\"figures\")\n",
    "    \n",
    "# subdirectory for our qualitative figures\n",
    "if \"quantitative\" not in os.listdir(\"figures\"):\n",
    "    os.mkdir(\"figures/quantitative\")\n",
    "    \n",
    "# DO NOT USE GPU FOR SALIENCY MAPS\n",
    "device = torch.device(\"cpu\")\n",
    "    \n",
    "# friendly colors\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "          '#f781bf', '#a65628', '#984ea3',\n",
    "          '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "# command-line arguments - let's go 10 IMAGES PER CLASS\n",
    "dataset = \"MNIST\" # [\"MNIST\", \"FashionMNIST\", \"CIFAR10\"][int(sys.argv[1])] # either 0, 1, or 2\n",
    "difficulty_val = \"easiest\" # [\"easiest\", \"hardest\", \"overall\"][int(sys.argv[2])] # either 0, 1, or 2\n",
    "split_val = \"train\" # [\"train\", \"test\"][int(sys.argv[3])] # either 0 or 1\n",
    "class_label_val = 0 # int(sys.argv[4]) # either 0, 1, 2, ..., or 9\n",
    "batch_idx = 0 # int(sys.argv[5]) # either 0, 1, 2, ..., or 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60e19f",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80465a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "886539bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the appropriate dataset + scores\n",
    "if dataset == \"MNIST\":\n",
    "\n",
    "    # load our training and test data\n",
    "    data_train = MNIST(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "    data_test = MNIST(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "\n",
    "    # load in our log files too\n",
    "    train_scores = pd.read_csv(\"logs/mnist_train_scores.csv\")\n",
    "    test_scores = pd.read_csv(\"logs/mnist_test_scores.csv\")\n",
    "    \n",
    "elif dataset == \"FashionMNIST\":\n",
    "    \n",
    "    # load our training and test data\n",
    "    data_train = FashionMNIST(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "    data_test = FashionMNIST(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "\n",
    "    # load in our log files too\n",
    "    train_scores = pd.read_csv(\"logs/fashion-mnist_train_scores.csv\")\n",
    "    test_scores = pd.read_csv(\"logs/fashion-mnist_test_scores.csv\")\n",
    "    \n",
    "elif dataset == \"CIFAR10\":\n",
    "    \n",
    "    # load our training and test data\n",
    "    data_train = CIFAR10(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "    data_test = CIFAR10(root=\"./data\", train=False, download=True, transform=train_transforms)\n",
    "\n",
    "    # load in our log files too\n",
    "    train_scores = pd.read_csv(\"logs/cifar10_train_scores.csv\")\n",
    "    test_scores = pd.read_csv(\"logs/cifar10_test_scores.csv\")\n",
    "\n",
    "# compute the difficulties of each train and test point\n",
    "train_difficulties = train_scores[train_scores.columns[4:]].mean(axis=0).values\n",
    "test_difficulties = test_scores[test_scores.columns[4:]].mean(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b747380b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f001eadf3d4c1f89e3b4c516074435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set a seed\n",
    "np.random.seed(858)\n",
    "torch.manual_seed(858)\n",
    "\n",
    "# how many images are we looking at per class?\n",
    "N_SAMPLES = 100\n",
    "\n",
    "# are we looking at easiest, hardest, or overall?\n",
    "for difficulty in [difficulty_val]:\n",
    "\n",
    "    # go thru both train + test splits\n",
    "    for split in [split_val]:\n",
    "        \n",
    "        # create our subplots here!\n",
    "    \n",
    "        # go thru each of our classes\n",
    "        for class_label in [class_label_val]:\n",
    "\n",
    "            # get the N_SAMPLES images that correspond to difficulty + class_label + split\n",
    "            if split == \"train\":\n",
    "                \n",
    "                # query all data points + difficulties corres. to this class, pick our N_SAMPLES\n",
    "                if dataset == \"CIFAR10\":\n",
    "                    class_idxs = np.argwhere(np.array(data_train.targets) == class_label).flatten()\n",
    "                else:\n",
    "                    class_idxs = np.argwhere(data_train.targets.numpy() == class_label).flatten()\n",
    "                class_train_difficulties = train_difficulties[class_idxs]\n",
    "                \n",
    "                # pick our indices\n",
    "                if difficulty == \"hardest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_train_difficulties)][:N_SAMPLES]\n",
    "                elif difficulty == \"easiest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_train_difficulties)][-N_SAMPLES:]\n",
    "                elif difficulty == \"overall\":\n",
    "                    class_sample_idxs = np.random.choice(class_idxs, size=N_SAMPLES, replace=False)\n",
    "                    \n",
    "            elif split == \"test\":\n",
    "                \n",
    "                # query all data points + difficulties that correspond to this class\n",
    "                if dataset == \"CIFAR10\":\n",
    "                    class_idxs = np.argwhere(np.array(data_test.targets) == class_label).flatten()\n",
    "                else:\n",
    "                    class_idxs = np.argwhere(data_test.targets.numpy() == class_label).flatten()\n",
    "                class_test_difficulties = test_difficulties[class_idxs]\n",
    "                \n",
    "                # pick our indices\n",
    "                if difficulty == \"hardest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_test_difficulties)][:N_SAMPLES]\n",
    "                elif difficulty == \"easiest\":\n",
    "                    class_sample_idxs = class_idxs[np.argsort(class_test_difficulties)][-N_SAMPLES:]\n",
    "                elif difficulty == \"overall\":\n",
    "                    class_sample_idxs = np.random.choice(class_idxs, size=N_SAMPLES, replace=False)\n",
    "                \n",
    "            # go thru each of our images + compute the 450 saliency maps on this batch of 10 images!\n",
    "            for class_sample_idx in class_sample_idxs[batch_idx*10:(batch_idx*10)+10]:\n",
    "                \n",
    "                # get the image that we should be working with, reshape + move to GPU\n",
    "                img = data_train[class_sample_idx][0] if split == \"train\" else data_test[class_sample_idx][0]\n",
    "                img = img.reshape(1, *img.shape)\n",
    "                img = img.to(device)\n",
    "                \n",
    "                # for CIFAR10, we need CNN(25, 47, 100), RESNET(20,32,44)\n",
    "                if dataset == \"CIFAR10\":\n",
    "                    model_packs = [(utils.CIFAR_CNN25K(), \"cnn_params=025k\"), \n",
    "                                   (utils.CIFAR_CNN47K(), \"cnn_params=047k\"),\n",
    "                                   (utils.CIFAR_CNN100K(), \"cnn_params=100k\"),\n",
    "                                   (resnet20(), \"resnet_variant=20\"),\n",
    "                                   (resnet32(), \"resnet_variant=32\"),\n",
    "                                   (resnet44(), \"resnet_variant=44\")]\n",
    "                \n",
    "                # for MNIST + FashionMNIST, generate saliencies for all 9 models MLP(1,2,3), CNN(2,3,4), RESNET(20,32,44)\n",
    "                elif dataset != \"CIFAR10\":\n",
    "                    model_packs = [(utils.MNIST_MLP(num_layers=1, data_dim=1024), \"mlp_num-layers=1\"), \n",
    "                                   (utils.MNIST_MLP(num_layers=2, data_dim=1024), \"mlp_num-layers=2\"),\n",
    "                                   (utils.MNIST_MLP(num_layers=3, data_dim=1024), \"mlp_num-layers=3\"),\n",
    "                                   (utils.MNIST_CNN(num_modules=2), \"cnn_num-modules=2\"), \n",
    "                                   (utils.MNIST_CNN(num_modules=3), \"cnn_num-modules=3\"),\n",
    "                                   (utils.MNIST_CNN(num_modules=4), \"cnn_num-modules=4\"),\n",
    "                                   (resnet20(), \"resnet_variant=20\"),\n",
    "                                   (resnet32(), \"resnet_variant=32\"),\n",
    "                                   (resnet44(), \"resnet_variant=44\")]\n",
    "                    \n",
    "                    \n",
    "\n",
    "                # create a dictionary for the STACKED saliency maps for each of our 9x models\n",
    "                saliency_maps = {}\n",
    "\n",
    "                # go thru all 6x or 9x of our models, all 50 seeds apiece\n",
    "                for model, model_desc in model_packs:\n",
    "\n",
    "                    # create an entry in our dictionary for this model + iterate thru the seeds\n",
    "                    saliency_maps[model_desc] = []\n",
    "                    for seed in range(50):\n",
    "\n",
    "                        # load in the correct weights + set to eval mode\n",
    "                        model.load_state_dict(torch.load(f\"models/{dataset}/{model_desc}_seed={str(seed).zfill(3)}/099.pth\", \n",
    "                                                         map_location=\"cpu\"))\n",
    "                        model.eval(); model.to(device)\n",
    "\n",
    "                        # compute our SmoothGrad saliency map, accounting for resnet dimensions\n",
    "                        smooth_grad = SmoothGrad(pretrained_model=model, cuda=False, n_samples=50, magnitude=False)\n",
    "                        if (\"resnet\" in model_desc) and (dataset != \"CIFAR10\"):\n",
    "                            saliency_map = smooth_grad(torch.cat([img, img, img], dim=1), index=None)\n",
    "                        else:\n",
    "                            saliency_map = smooth_grad(img, index=None)\n",
    "                        saliency_map_2d = np.sum(saliency_map, axis=0)\n",
    "\n",
    "                        # add to our dictionary\n",
    "                        saliency_maps[model_desc].append(copy.deepcopy(saliency_map_2d))\n",
    "\n",
    "                # save our object as a .pickle so that we can load it for analyses later\n",
    "                with open(f\"maps/{dataset}/{fname}\", \"wb\") as file:\n",
    "                    pickle.dump(obj=saliency_maps, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef59395f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14b9297f76d0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(data_train[class_sample_idx][0].numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "725cdcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn_num-modules=2_seed=000',\n",
       " 'cnn_num-modules=2_seed=001',\n",
       " 'cnn_num-modules=2_seed=002',\n",
       " 'cnn_num-modules=2_seed=003',\n",
       " 'cnn_num-modules=2_seed=004',\n",
       " 'cnn_num-modules=2_seed=005',\n",
       " 'cnn_num-modules=2_seed=006',\n",
       " 'cnn_num-modules=2_seed=007',\n",
       " 'cnn_num-modules=2_seed=008',\n",
       " 'cnn_num-modules=2_seed=009',\n",
       " 'cnn_num-modules=2_seed=010',\n",
       " 'cnn_num-modules=2_seed=011',\n",
       " 'cnn_num-modules=2_seed=012',\n",
       " 'cnn_num-modules=2_seed=013',\n",
       " 'cnn_num-modules=2_seed=014',\n",
       " 'cnn_num-modules=2_seed=015',\n",
       " 'cnn_num-modules=2_seed=016',\n",
       " 'cnn_num-modules=2_seed=017',\n",
       " 'cnn_num-modules=2_seed=018',\n",
       " 'cnn_num-modules=2_seed=019',\n",
       " 'cnn_num-modules=2_seed=020',\n",
       " 'cnn_num-modules=2_seed=021',\n",
       " 'cnn_num-modules=2_seed=022',\n",
       " 'cnn_num-modules=2_seed=023',\n",
       " 'cnn_num-modules=2_seed=024',\n",
       " 'cnn_num-modules=2_seed=025',\n",
       " 'cnn_num-modules=2_seed=026',\n",
       " 'cnn_num-modules=2_seed=027',\n",
       " 'cnn_num-modules=2_seed=028',\n",
       " 'cnn_num-modules=2_seed=029',\n",
       " 'cnn_num-modules=2_seed=030',\n",
       " 'cnn_num-modules=2_seed=031',\n",
       " 'cnn_num-modules=2_seed=032',\n",
       " 'cnn_num-modules=2_seed=033',\n",
       " 'cnn_num-modules=2_seed=034',\n",
       " 'cnn_num-modules=2_seed=035',\n",
       " 'cnn_num-modules=2_seed=036',\n",
       " 'cnn_num-modules=2_seed=037',\n",
       " 'cnn_num-modules=2_seed=038',\n",
       " 'cnn_num-modules=2_seed=039',\n",
       " 'cnn_num-modules=2_seed=040',\n",
       " 'cnn_num-modules=2_seed=041',\n",
       " 'cnn_num-modules=2_seed=042',\n",
       " 'cnn_num-modules=2_seed=043',\n",
       " 'cnn_num-modules=2_seed=044',\n",
       " 'cnn_num-modules=2_seed=045',\n",
       " 'cnn_num-modules=2_seed=046',\n",
       " 'cnn_num-modules=2_seed=047',\n",
       " 'cnn_num-modules=2_seed=048',\n",
       " 'cnn_num-modules=2_seed=049',\n",
       " 'cnn_num-modules=3_seed=000',\n",
       " 'cnn_num-modules=3_seed=001',\n",
       " 'cnn_num-modules=3_seed=002',\n",
       " 'cnn_num-modules=3_seed=003',\n",
       " 'cnn_num-modules=3_seed=004',\n",
       " 'cnn_num-modules=3_seed=005',\n",
       " 'cnn_num-modules=3_seed=006',\n",
       " 'cnn_num-modules=3_seed=007',\n",
       " 'cnn_num-modules=3_seed=008',\n",
       " 'cnn_num-modules=3_seed=009',\n",
       " 'cnn_num-modules=3_seed=010',\n",
       " 'cnn_num-modules=3_seed=011',\n",
       " 'cnn_num-modules=3_seed=012',\n",
       " 'cnn_num-modules=3_seed=013',\n",
       " 'cnn_num-modules=3_seed=014',\n",
       " 'cnn_num-modules=3_seed=015',\n",
       " 'cnn_num-modules=3_seed=016',\n",
       " 'cnn_num-modules=3_seed=017',\n",
       " 'cnn_num-modules=3_seed=018',\n",
       " 'cnn_num-modules=3_seed=019',\n",
       " 'cnn_num-modules=3_seed=020',\n",
       " 'cnn_num-modules=3_seed=021',\n",
       " 'cnn_num-modules=3_seed=022',\n",
       " 'cnn_num-modules=3_seed=023',\n",
       " 'cnn_num-modules=3_seed=024',\n",
       " 'cnn_num-modules=3_seed=025',\n",
       " 'cnn_num-modules=3_seed=026',\n",
       " 'cnn_num-modules=3_seed=027',\n",
       " 'cnn_num-modules=3_seed=028',\n",
       " 'cnn_num-modules=3_seed=029',\n",
       " 'cnn_num-modules=3_seed=030',\n",
       " 'cnn_num-modules=3_seed=031',\n",
       " 'cnn_num-modules=3_seed=032',\n",
       " 'cnn_num-modules=3_seed=033',\n",
       " 'cnn_num-modules=3_seed=034',\n",
       " 'cnn_num-modules=3_seed=035',\n",
       " 'cnn_num-modules=3_seed=036',\n",
       " 'cnn_num-modules=3_seed=037',\n",
       " 'cnn_num-modules=3_seed=038',\n",
       " 'cnn_num-modules=3_seed=039',\n",
       " 'cnn_num-modules=3_seed=040',\n",
       " 'cnn_num-modules=3_seed=041',\n",
       " 'cnn_num-modules=3_seed=042',\n",
       " 'cnn_num-modules=3_seed=043',\n",
       " 'cnn_num-modules=3_seed=044',\n",
       " 'cnn_num-modules=3_seed=045',\n",
       " 'cnn_num-modules=3_seed=046',\n",
       " 'cnn_num-modules=3_seed=047',\n",
       " 'cnn_num-modules=3_seed=048',\n",
       " 'cnn_num-modules=3_seed=049',\n",
       " 'cnn_num-modules=4_seed=000',\n",
       " 'cnn_num-modules=4_seed=001',\n",
       " 'cnn_num-modules=4_seed=002',\n",
       " 'cnn_num-modules=4_seed=003',\n",
       " 'cnn_num-modules=4_seed=004',\n",
       " 'cnn_num-modules=4_seed=005',\n",
       " 'cnn_num-modules=4_seed=006',\n",
       " 'cnn_num-modules=4_seed=007',\n",
       " 'cnn_num-modules=4_seed=008',\n",
       " 'cnn_num-modules=4_seed=009',\n",
       " 'cnn_num-modules=4_seed=010',\n",
       " 'cnn_num-modules=4_seed=011',\n",
       " 'cnn_num-modules=4_seed=012',\n",
       " 'cnn_num-modules=4_seed=013',\n",
       " 'cnn_num-modules=4_seed=014',\n",
       " 'cnn_num-modules=4_seed=015',\n",
       " 'cnn_num-modules=4_seed=016',\n",
       " 'cnn_num-modules=4_seed=017',\n",
       " 'cnn_num-modules=4_seed=018',\n",
       " 'cnn_num-modules=4_seed=019',\n",
       " 'cnn_num-modules=4_seed=020',\n",
       " 'cnn_num-modules=4_seed=021',\n",
       " 'cnn_num-modules=4_seed=022',\n",
       " 'cnn_num-modules=4_seed=023',\n",
       " 'cnn_num-modules=4_seed=024',\n",
       " 'cnn_num-modules=4_seed=025',\n",
       " 'cnn_num-modules=4_seed=026',\n",
       " 'cnn_num-modules=4_seed=027',\n",
       " 'cnn_num-modules=4_seed=028',\n",
       " 'cnn_num-modules=4_seed=029',\n",
       " 'cnn_num-modules=4_seed=030',\n",
       " 'cnn_num-modules=4_seed=031',\n",
       " 'cnn_num-modules=4_seed=032',\n",
       " 'cnn_num-modules=4_seed=033',\n",
       " 'cnn_num-modules=4_seed=034',\n",
       " 'cnn_num-modules=4_seed=035',\n",
       " 'cnn_num-modules=4_seed=036',\n",
       " 'cnn_num-modules=4_seed=037',\n",
       " 'cnn_num-modules=4_seed=038',\n",
       " 'cnn_num-modules=4_seed=039',\n",
       " 'cnn_num-modules=4_seed=040',\n",
       " 'cnn_num-modules=4_seed=041',\n",
       " 'cnn_num-modules=4_seed=042',\n",
       " 'cnn_num-modules=4_seed=043',\n",
       " 'cnn_num-modules=4_seed=044',\n",
       " 'cnn_num-modules=4_seed=045',\n",
       " 'cnn_num-modules=4_seed=046',\n",
       " 'cnn_num-modules=4_seed=047',\n",
       " 'cnn_num-modules=4_seed=048',\n",
       " 'cnn_num-modules=4_seed=049',\n",
       " 'mlp_num-layers=1_seed=000',\n",
       " 'mlp_num-layers=1_seed=001',\n",
       " 'mlp_num-layers=1_seed=002',\n",
       " 'mlp_num-layers=1_seed=003',\n",
       " 'mlp_num-layers=1_seed=004',\n",
       " 'mlp_num-layers=1_seed=005',\n",
       " 'mlp_num-layers=1_seed=006',\n",
       " 'mlp_num-layers=1_seed=007',\n",
       " 'mlp_num-layers=1_seed=008',\n",
       " 'mlp_num-layers=1_seed=009',\n",
       " 'mlp_num-layers=1_seed=010',\n",
       " 'mlp_num-layers=1_seed=011',\n",
       " 'mlp_num-layers=1_seed=012',\n",
       " 'mlp_num-layers=1_seed=013',\n",
       " 'mlp_num-layers=1_seed=014',\n",
       " 'mlp_num-layers=1_seed=015',\n",
       " 'mlp_num-layers=1_seed=016',\n",
       " 'mlp_num-layers=1_seed=017',\n",
       " 'mlp_num-layers=1_seed=018',\n",
       " 'mlp_num-layers=1_seed=019',\n",
       " 'mlp_num-layers=1_seed=020',\n",
       " 'mlp_num-layers=1_seed=021',\n",
       " 'mlp_num-layers=1_seed=022',\n",
       " 'mlp_num-layers=1_seed=023',\n",
       " 'mlp_num-layers=1_seed=024',\n",
       " 'mlp_num-layers=1_seed=025',\n",
       " 'mlp_num-layers=1_seed=026',\n",
       " 'mlp_num-layers=1_seed=027',\n",
       " 'mlp_num-layers=1_seed=028',\n",
       " 'mlp_num-layers=1_seed=029',\n",
       " 'mlp_num-layers=1_seed=030',\n",
       " 'mlp_num-layers=1_seed=031',\n",
       " 'mlp_num-layers=1_seed=032',\n",
       " 'mlp_num-layers=1_seed=033',\n",
       " 'mlp_num-layers=1_seed=034',\n",
       " 'mlp_num-layers=1_seed=035',\n",
       " 'mlp_num-layers=1_seed=036',\n",
       " 'mlp_num-layers=1_seed=037',\n",
       " 'mlp_num-layers=1_seed=038',\n",
       " 'mlp_num-layers=1_seed=039',\n",
       " 'mlp_num-layers=1_seed=040',\n",
       " 'mlp_num-layers=1_seed=041',\n",
       " 'mlp_num-layers=1_seed=042',\n",
       " 'mlp_num-layers=1_seed=043',\n",
       " 'mlp_num-layers=1_seed=044',\n",
       " 'mlp_num-layers=1_seed=045',\n",
       " 'mlp_num-layers=1_seed=046',\n",
       " 'mlp_num-layers=1_seed=047',\n",
       " 'mlp_num-layers=1_seed=048',\n",
       " 'mlp_num-layers=1_seed=049',\n",
       " 'mlp_num-layers=2_seed=000',\n",
       " 'mlp_num-layers=2_seed=001',\n",
       " 'mlp_num-layers=2_seed=002',\n",
       " 'mlp_num-layers=2_seed=003',\n",
       " 'mlp_num-layers=2_seed=004',\n",
       " 'mlp_num-layers=2_seed=005',\n",
       " 'mlp_num-layers=2_seed=006',\n",
       " 'mlp_num-layers=2_seed=007',\n",
       " 'mlp_num-layers=2_seed=008',\n",
       " 'mlp_num-layers=2_seed=009',\n",
       " 'mlp_num-layers=2_seed=010',\n",
       " 'mlp_num-layers=2_seed=011',\n",
       " 'mlp_num-layers=2_seed=012',\n",
       " 'mlp_num-layers=2_seed=013',\n",
       " 'mlp_num-layers=2_seed=014',\n",
       " 'mlp_num-layers=2_seed=015',\n",
       " 'mlp_num-layers=2_seed=016',\n",
       " 'mlp_num-layers=2_seed=017',\n",
       " 'mlp_num-layers=2_seed=018',\n",
       " 'mlp_num-layers=2_seed=019',\n",
       " 'mlp_num-layers=2_seed=020',\n",
       " 'mlp_num-layers=2_seed=021',\n",
       " 'mlp_num-layers=2_seed=022',\n",
       " 'mlp_num-layers=2_seed=023',\n",
       " 'mlp_num-layers=2_seed=024',\n",
       " 'mlp_num-layers=2_seed=025',\n",
       " 'mlp_num-layers=2_seed=026',\n",
       " 'mlp_num-layers=2_seed=027',\n",
       " 'mlp_num-layers=2_seed=028',\n",
       " 'mlp_num-layers=2_seed=029',\n",
       " 'mlp_num-layers=2_seed=030',\n",
       " 'mlp_num-layers=2_seed=031',\n",
       " 'mlp_num-layers=2_seed=032',\n",
       " 'mlp_num-layers=2_seed=033',\n",
       " 'mlp_num-layers=2_seed=034',\n",
       " 'mlp_num-layers=2_seed=035',\n",
       " 'mlp_num-layers=2_seed=036',\n",
       " 'mlp_num-layers=2_seed=037',\n",
       " 'mlp_num-layers=2_seed=038',\n",
       " 'mlp_num-layers=2_seed=039',\n",
       " 'mlp_num-layers=2_seed=040',\n",
       " 'mlp_num-layers=2_seed=041',\n",
       " 'mlp_num-layers=2_seed=042',\n",
       " 'mlp_num-layers=2_seed=043',\n",
       " 'mlp_num-layers=2_seed=044',\n",
       " 'mlp_num-layers=2_seed=045',\n",
       " 'mlp_num-layers=2_seed=046',\n",
       " 'mlp_num-layers=2_seed=047',\n",
       " 'mlp_num-layers=2_seed=048',\n",
       " 'mlp_num-layers=2_seed=049',\n",
       " 'mlp_num-layers=3_seed=000',\n",
       " 'mlp_num-layers=3_seed=001',\n",
       " 'mlp_num-layers=3_seed=002',\n",
       " 'mlp_num-layers=3_seed=003',\n",
       " 'mlp_num-layers=3_seed=004',\n",
       " 'mlp_num-layers=3_seed=005',\n",
       " 'mlp_num-layers=3_seed=006',\n",
       " 'mlp_num-layers=3_seed=007',\n",
       " 'mlp_num-layers=3_seed=008',\n",
       " 'mlp_num-layers=3_seed=009',\n",
       " 'mlp_num-layers=3_seed=010',\n",
       " 'mlp_num-layers=3_seed=011',\n",
       " 'mlp_num-layers=3_seed=012',\n",
       " 'mlp_num-layers=3_seed=013',\n",
       " 'mlp_num-layers=3_seed=014',\n",
       " 'mlp_num-layers=3_seed=015',\n",
       " 'mlp_num-layers=3_seed=016',\n",
       " 'mlp_num-layers=3_seed=017',\n",
       " 'mlp_num-layers=3_seed=018',\n",
       " 'mlp_num-layers=3_seed=019',\n",
       " 'mlp_num-layers=3_seed=020',\n",
       " 'mlp_num-layers=3_seed=021',\n",
       " 'mlp_num-layers=3_seed=022',\n",
       " 'mlp_num-layers=3_seed=023',\n",
       " 'mlp_num-layers=3_seed=024',\n",
       " 'mlp_num-layers=3_seed=025',\n",
       " 'mlp_num-layers=3_seed=026',\n",
       " 'mlp_num-layers=3_seed=027',\n",
       " 'mlp_num-layers=3_seed=028',\n",
       " 'mlp_num-layers=3_seed=029',\n",
       " 'mlp_num-layers=3_seed=030',\n",
       " 'mlp_num-layers=3_seed=031',\n",
       " 'mlp_num-layers=3_seed=032',\n",
       " 'mlp_num-layers=3_seed=033',\n",
       " 'mlp_num-layers=3_seed=034',\n",
       " 'mlp_num-layers=3_seed=035',\n",
       " 'mlp_num-layers=3_seed=036',\n",
       " 'mlp_num-layers=3_seed=037',\n",
       " 'mlp_num-layers=3_seed=038',\n",
       " 'mlp_num-layers=3_seed=039',\n",
       " 'mlp_num-layers=3_seed=040',\n",
       " 'mlp_num-layers=3_seed=041',\n",
       " 'mlp_num-layers=3_seed=042',\n",
       " 'mlp_num-layers=3_seed=043',\n",
       " 'mlp_num-layers=3_seed=044',\n",
       " 'mlp_num-layers=3_seed=045',\n",
       " 'mlp_num-layers=3_seed=046',\n",
       " 'mlp_num-layers=3_seed=047',\n",
       " 'mlp_num-layers=3_seed=048',\n",
       " 'mlp_num-layers=3_seed=049',\n",
       " 'resnet_variant=20_seed=000',\n",
       " 'resnet_variant=20_seed=001',\n",
       " 'resnet_variant=20_seed=002',\n",
       " 'resnet_variant=20_seed=003',\n",
       " 'resnet_variant=20_seed=004',\n",
       " 'resnet_variant=20_seed=005',\n",
       " 'resnet_variant=20_seed=006',\n",
       " 'resnet_variant=20_seed=007',\n",
       " 'resnet_variant=20_seed=008',\n",
       " 'resnet_variant=20_seed=009',\n",
       " 'resnet_variant=20_seed=010',\n",
       " 'resnet_variant=20_seed=011',\n",
       " 'resnet_variant=20_seed=012',\n",
       " 'resnet_variant=20_seed=013',\n",
       " 'resnet_variant=20_seed=014',\n",
       " 'resnet_variant=20_seed=015',\n",
       " 'resnet_variant=20_seed=016',\n",
       " 'resnet_variant=20_seed=017',\n",
       " 'resnet_variant=20_seed=018',\n",
       " 'resnet_variant=20_seed=019',\n",
       " 'resnet_variant=20_seed=020',\n",
       " 'resnet_variant=20_seed=021',\n",
       " 'resnet_variant=20_seed=022',\n",
       " 'resnet_variant=20_seed=023',\n",
       " 'resnet_variant=20_seed=024',\n",
       " 'resnet_variant=20_seed=025',\n",
       " 'resnet_variant=20_seed=026',\n",
       " 'resnet_variant=20_seed=027',\n",
       " 'resnet_variant=20_seed=028',\n",
       " 'resnet_variant=20_seed=029',\n",
       " 'resnet_variant=20_seed=030',\n",
       " 'resnet_variant=20_seed=031',\n",
       " 'resnet_variant=20_seed=032',\n",
       " 'resnet_variant=20_seed=033',\n",
       " 'resnet_variant=20_seed=034',\n",
       " 'resnet_variant=20_seed=035',\n",
       " 'resnet_variant=20_seed=036',\n",
       " 'resnet_variant=20_seed=037',\n",
       " 'resnet_variant=20_seed=038',\n",
       " 'resnet_variant=20_seed=039',\n",
       " 'resnet_variant=20_seed=040',\n",
       " 'resnet_variant=20_seed=041',\n",
       " 'resnet_variant=20_seed=042',\n",
       " 'resnet_variant=20_seed=043',\n",
       " 'resnet_variant=20_seed=044',\n",
       " 'resnet_variant=20_seed=045',\n",
       " 'resnet_variant=20_seed=046',\n",
       " 'resnet_variant=20_seed=047',\n",
       " 'resnet_variant=20_seed=048',\n",
       " 'resnet_variant=20_seed=049',\n",
       " 'resnet_variant=32_seed=000',\n",
       " 'resnet_variant=32_seed=001',\n",
       " 'resnet_variant=32_seed=002',\n",
       " 'resnet_variant=32_seed=003',\n",
       " 'resnet_variant=32_seed=004',\n",
       " 'resnet_variant=32_seed=005',\n",
       " 'resnet_variant=32_seed=006',\n",
       " 'resnet_variant=32_seed=007',\n",
       " 'resnet_variant=32_seed=008',\n",
       " 'resnet_variant=32_seed=009',\n",
       " 'resnet_variant=32_seed=010',\n",
       " 'resnet_variant=32_seed=011',\n",
       " 'resnet_variant=32_seed=012',\n",
       " 'resnet_variant=32_seed=013',\n",
       " 'resnet_variant=32_seed=014',\n",
       " 'resnet_variant=32_seed=015',\n",
       " 'resnet_variant=32_seed=016',\n",
       " 'resnet_variant=32_seed=017',\n",
       " 'resnet_variant=32_seed=018',\n",
       " 'resnet_variant=32_seed=019',\n",
       " 'resnet_variant=32_seed=020',\n",
       " 'resnet_variant=32_seed=021',\n",
       " 'resnet_variant=32_seed=022',\n",
       " 'resnet_variant=32_seed=023',\n",
       " 'resnet_variant=32_seed=024',\n",
       " 'resnet_variant=32_seed=025',\n",
       " 'resnet_variant=32_seed=026',\n",
       " 'resnet_variant=32_seed=027',\n",
       " 'resnet_variant=32_seed=028',\n",
       " 'resnet_variant=32_seed=029',\n",
       " 'resnet_variant=32_seed=030',\n",
       " 'resnet_variant=32_seed=031',\n",
       " 'resnet_variant=32_seed=032',\n",
       " 'resnet_variant=32_seed=033',\n",
       " 'resnet_variant=32_seed=034',\n",
       " 'resnet_variant=32_seed=035',\n",
       " 'resnet_variant=32_seed=036',\n",
       " 'resnet_variant=32_seed=037',\n",
       " 'resnet_variant=32_seed=038',\n",
       " 'resnet_variant=32_seed=039',\n",
       " 'resnet_variant=32_seed=040',\n",
       " 'resnet_variant=32_seed=041',\n",
       " 'resnet_variant=32_seed=042',\n",
       " 'resnet_variant=32_seed=043',\n",
       " 'resnet_variant=32_seed=044',\n",
       " 'resnet_variant=32_seed=045',\n",
       " 'resnet_variant=32_seed=046',\n",
       " 'resnet_variant=32_seed=047',\n",
       " 'resnet_variant=32_seed=048',\n",
       " 'resnet_variant=32_seed=049',\n",
       " 'resnet_variant=44_seed=000',\n",
       " 'resnet_variant=44_seed=001',\n",
       " 'resnet_variant=44_seed=002',\n",
       " 'resnet_variant=44_seed=003',\n",
       " 'resnet_variant=44_seed=004',\n",
       " 'resnet_variant=44_seed=005',\n",
       " 'resnet_variant=44_seed=006',\n",
       " 'resnet_variant=44_seed=007',\n",
       " 'resnet_variant=44_seed=008',\n",
       " 'resnet_variant=44_seed=009',\n",
       " 'resnet_variant=44_seed=010',\n",
       " 'resnet_variant=44_seed=011',\n",
       " 'resnet_variant=44_seed=012',\n",
       " 'resnet_variant=44_seed=013',\n",
       " 'resnet_variant=44_seed=014',\n",
       " 'resnet_variant=44_seed=015',\n",
       " 'resnet_variant=44_seed=016',\n",
       " 'resnet_variant=44_seed=017',\n",
       " 'resnet_variant=44_seed=018',\n",
       " 'resnet_variant=44_seed=019',\n",
       " 'resnet_variant=44_seed=020',\n",
       " 'resnet_variant=44_seed=021',\n",
       " 'resnet_variant=44_seed=022',\n",
       " 'resnet_variant=44_seed=023',\n",
       " 'resnet_variant=44_seed=024',\n",
       " 'resnet_variant=44_seed=025',\n",
       " 'resnet_variant=44_seed=026',\n",
       " 'resnet_variant=44_seed=027',\n",
       " 'resnet_variant=44_seed=028',\n",
       " 'resnet_variant=44_seed=029',\n",
       " 'resnet_variant=44_seed=030',\n",
       " 'resnet_variant=44_seed=031',\n",
       " 'resnet_variant=44_seed=032',\n",
       " 'resnet_variant=44_seed=033',\n",
       " 'resnet_variant=44_seed=034',\n",
       " 'resnet_variant=44_seed=035',\n",
       " 'resnet_variant=44_seed=036',\n",
       " 'resnet_variant=44_seed=037',\n",
       " 'resnet_variant=44_seed=038',\n",
       " 'resnet_variant=44_seed=039',\n",
       " 'resnet_variant=44_seed=040',\n",
       " 'resnet_variant=44_seed=041',\n",
       " 'resnet_variant=44_seed=042',\n",
       " 'resnet_variant=44_seed=043',\n",
       " 'resnet_variant=44_seed=044',\n",
       " 'resnet_variant=44_seed=045',\n",
       " 'resnet_variant=44_seed=046',\n",
       " 'resnet_variant=44_seed=047',\n",
       " 'resnet_variant=44_seed=048',\n",
       " 'resnet_variant=44_seed=049']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(\"models/MNIST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b52ab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for MNIST + FashionMNIST, generate saliencies for all 9 models MLP(1,2,3), CNN(2,3,4), RESNET(20,32,44)\n",
    "model_packs = [(utils.MNIST_MLP(num_layers=1, data_dim=1024), \"mlp_num-layers=1\"), \n",
    "               (utils.MNIST_MLP(num_layers=2, data_dim=1024), \"mlp_num-layers=2\"),\n",
    "               (utils.MNIST_MLP(num_layers=3, data_dim=1024), \"mlp_num-layers=3\"), \n",
    "               (utils.MNIST_CNN(num_modules=2), \"cnn_num-modules=2\"), \n",
    "               (utils.MNIST_CNN(num_modules=3), \"cnn_num-modules=3\"),\n",
    "               (utils.MNIST_CNN(num_modules=4), \"cnn_num-modules=4\"),\n",
    "               (resnet20(), \"resnet_variant=20\"),\n",
    "               (resnet32(), \"resnet_variant=32\"),\n",
    "               (resnet44(), \"resnet_variant=44\")]\n",
    "\n",
    "# create a dictionary for the STACKED saliency maps for each of our 9x models\n",
    "saliency_maps = {}\n",
    "\n",
    "# go thru all 9x of our models, all 50 seeds apiece\n",
    "for model, model_desc in tqdm(model_packs):\n",
    "    \n",
    "    # create an entry in our dictionary for this model + iterate thru the seeds\n",
    "    saliency_maps[model_desc] = []\n",
    "    for seed in range(50):\n",
    "        \n",
    "        # load in the correct weights + set to eval mode\n",
    "        model.load_state_dict(torch.load(f\"models/{dataset}/{model_desc}_seed={str(seed).zfill(3)}/099.pth\", \n",
    "                                         map_location=\"cpu\"))\n",
    "        model.eval(); model.to(device)\n",
    "        \n",
    "        # compute our SmoothGrad saliency map, accounting for resnet dimensions\n",
    "        smooth_grad = SmoothGrad(pretrained_model=model, cuda=False, n_samples=50, magnitude=False)\n",
    "        if \"resnet\" in model_desc:\n",
    "            saliency_map = smooth_grad(torch.cat([img, img, img], dim=1), index=None)\n",
    "        else:\n",
    "            saliency_map = smooth_grad(img, index=None)\n",
    "        saliency_map_2d = np.sum(saliency_map, axis=0)\n",
    "        \n",
    "        # add to our dictionary\n",
    "        saliency_maps[model_desc].append(copy.deepcopy(saliency_map_2d))\n",
    "        \n",
    "# save our object as a .pickle so that we can load it for analyses later\n",
    "with open(f\"maps/{dataset}/{fname}\", \"wb\") as file:\n",
    "    pickle.dump(obj=saliency_maps, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19dd982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"maps/{dataset}/{fname}\", \"wb\") as file:\n",
    "    pickle.dump(obj=saliency_maps, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84f9f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"difficulty={difficulty}_split={split}_class-label={class_label}_idx={str(class_sample_idx).zfill(5)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "342a57c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MNIST', 'easiest', 'train', 0, 20731)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, difficulty, split, class_label, class_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aa6ec829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for j in range(3):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f4ca7c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Afterburner)",
   "language": "python",
   "name": "afterburner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
